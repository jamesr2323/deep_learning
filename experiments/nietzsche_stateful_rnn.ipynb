{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## All imports needed\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from fastai.io import *\n",
    "from fastai.conv_learner import *\n",
    "\n",
    "from fastai.column_data import *\n",
    "\n",
    "from torchtext import vocab, data\n",
    "\n",
    "from fastai.nlp import *\n",
    "from fastai.lm_rnn import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../data/nietzsche/'\n",
    "\n",
    "os.makedirs(PATH, exist_ok=True)\n",
    "os.makedirs(f'{PATH}trn', exist_ok=True)\n",
    "os.makedirs(f'{PATH}vld', exist_ok=True)\n",
    "\n",
    "urllib.request.urlretrieve(\"https://s3.amazonaws.com/text-datasets/nietzsche.txt\", f'{PATH}nietzsche.txt')\n",
    "\n",
    "# Put first 80% of text into trn and the rest into vld\n",
    "wc = !wc -l {PATH}nietzsche.txt\n",
    "wc = int(wc[0].split(' ')[0])\n",
    "\n",
    "trn_n = int(round(wc*0.8))\n",
    "vld_n = wc - trn_n\n",
    "\n",
    "!head -n {trn_n} {PATH}nietzsche.txt > {PATH}trn/text.txt\n",
    "!tail -n {vld_n} {PATH}nietzsche.txt > {PATH}vld/text.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build out model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = data.Field(lower=True, tokenize=list)\n",
    "bs=1024; bptt=8\n",
    "\n",
    "md = LanguageModelData.from_text_files(PATH, TEXT, train='trn', validation='vld', test='vld', bs=bs, bptt=bptt, min_freq=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharSeqStatefulRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac, n_hidden, bs):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.n_hidden = n_hidden\n",
    "        \n",
    "        # Layers\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.rnn = nn.RNN(n_fac, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        \n",
    "        # Hidden layers weights - start at zero\n",
    "        self.init_hidden(bs)\n",
    "        \n",
    "    def forward(self, cs):\n",
    "        bs = cs[0].size(0)\n",
    "        if self.h.size(1) != bs: self.init_hidden(bs)\n",
    "        \n",
    "        outp, h = self.rnn(self.e(cs), self.h)\n",
    "        self.h = repackage_var(h)\n",
    "        return F.log_softmax(self.l_out(outp), dim=-1).view(-1, self.vocab_size)        \n",
    "    \n",
    "    def init_hidden(self, bs):\n",
    "        self.h = V(torch.zeros(1, bs, self.n_hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e23a92eafde441beb58363d5043d98e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=6), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      1.890363   1.853279  \n",
      "    1      1.713616   1.708676                              \n",
      "    2      1.633962   1.643346                              \n",
      "    3      1.586952   1.598944                              \n",
      "    4      1.54269    1.577271                              \n",
      "    5      1.517579   1.558746                              \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.55875])]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = md.nt # Number of tokens\n",
    "n_hidden = 256\n",
    "bs = 512\n",
    "n_fac = 42\n",
    "\n",
    "m = CharSeqStatefulRNN(vocab_size, n_fac, n_hidden, bs)\n",
    "opt = optim.Adam(m.parameters(), 1e-3)\n",
    "\n",
    "fit(m, md, 6, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dfb7f4c44024c5587f00ea762700172",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=6), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      1.439679   1.519057  \n",
      "    1      1.445775   1.515631                              \n",
      "    2      1.447319   1.512792                              \n",
      "    3      1.443466   1.510369                              \n",
      "    4      1.433581   1.507999                              \n",
      "    5      1.430042   1.506103                              \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.5061])]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_lrs(opt, 1e-4)\n",
    "fit(m, md, 6, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharSeqStatefulGRU(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac, n_hidden, bs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.n_hidden = n_hidden\n",
    "        \n",
    "        # Layers\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.rnn = nn.GRU(n_fac, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        \n",
    "        self.init_hidden(bs)\n",
    "        \n",
    "    def forward(self, cs):\n",
    "        bs = cs[0].size(0)\n",
    "        if bs != self.h.size(1): self.init_hidden(bs)\n",
    "            \n",
    "        inp = F.relu(self.e(cs))\n",
    "        outp, h = self.rnn(inp, self.h)       \n",
    "        self.h = repackage_var(h)\n",
    "        \n",
    "        return F.log_softmax(self.l_out(outp), dim=-1).view(-1, self.vocab_size)\n",
    "    \n",
    "    def init_hidden(self, bs): \n",
    "        self.h = V(torch.zeros(1, bs, self.n_hidden)) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47ab794a4cf247f1a46a6c19dd15dbfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2%|‚ñè         | 23/942 [00:02<01:56,  7.87it/s, loss=3.16]\n",
      "epoch      trn_loss   val_loss                              \n",
      "    0      1.736408   1.707335  \n",
      "    1      1.52186    1.546684                              \n",
      "    2      1.421969   1.483831                              \n",
      "    3      1.35957    1.464814                              \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.46481])]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = CharSeqStatefulGRU(vocab_size=md.nt, n_fac=42, n_hidden=512, bs=1024)\n",
    "opt = optim.Adam(m.parameters(), 1e-3)\n",
    "fit(m, md, 4, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Val loss down to 1.46 - looking better. Let's try out word generation again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And yeten anconish poris fal, anty?--5y the cons strow insthemios. ever oftermento underancessentor. the mordistilian ething trus! fylike poso now dendirate desthasto _migreedourfor'\" inar.2--wility; ittanda\n",
      "And yet adabless!--fining undvicles stilious. in theas amplecian im),an butopatious, tas ourdepentlicy is merifare am he imations farility ofte masinged nautrone merthe forua idexperated inlity \"des assenalo\n",
      "And yeto1 culia it atte is culed; it some? in,with cers imous, fortal a gan this nothe sen lonyare\" do spemple, whoenestre assen the equitame ass of teaf fortal arte ope, welegets,\"16. l'shous, wily, nown ha\n"
     ]
    }
   ],
   "source": [
    "def get_next(inp):\n",
    "    idxs = TEXT.numericalize(inp, device=-1)\n",
    "    p = m(VV(idxs.transpose(0,1)))\n",
    "    r = torch.multinomial(p[-1].exp(), 1)\n",
    "    return TEXT.vocab.itos[to_np(r)[0]]\n",
    "\n",
    "print(get_next_n(\"And yet\", 200))\n",
    "print(get_next_n(\"And yet\", 200))\n",
    "print(get_next_n(\"And yet\", 200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it's starting to produce something - and crucially it's different on each step, which gives hope for a text generator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharSeqStatefulLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac, n_hidden, bs, nl):\n",
    "        super().__init__()\n",
    "        self.vocab_size,self.nl,self.n_hidden = vocab_size,nl,n_hidden\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.rnn = nn.LSTM(n_fac, n_hidden, nl, dropout=0.5)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        self.init_hidden(bs)\n",
    "        \n",
    "    def forward(self, cs):\n",
    "        bs = cs[0].size(0)\n",
    "        if self.h[0].size(1) != bs: self.init_hidden(bs)\n",
    "        outp,h = self.rnn(self.e(cs), self.h)\n",
    "        self.h = repackage_var(h)\n",
    "        return F.log_softmax(self.l_out(outp), dim=-1).view(-1, self.vocab_size)\n",
    "    \n",
    "    def init_hidden(self, bs):\n",
    "        self.h = (V(torch.zeros(self.nl, bs, self.n_hidden)),\n",
    "                  V(torch.zeros(self.nl, bs, self.n_hidden)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29c34cbc1f384ad4bc2d8b4cdffa746c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      1.737481   1.658057  \n",
      "    1      1.536371   1.500945                              \n",
      "    2      1.455958   1.440475                              \n",
      "    3      1.402662   1.410865                              \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.41086])]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = CharSeqStatefulLSTM(vocab_size=md.nt, n_fac=42, n_hidden=512, bs=1024, nl=2)\n",
    "opt = optim.Adam(m.parameters(), 1e-3)\n",
    "fit(m, md, 4, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And yethand the quily in ever itsthather accumous the begin was wettermus in aptifies uncous granteding withemoventlies a respectionas art. whick san adment in sty!--and: we he womed, insted to theavourwelf.\n",
      "And yeto'hand trivity thin said.121. he madeniky them the shows in this aptical assuburary of morto exive, skrious a purable from a my our feet! he was a mank ancifantant thicken gere, he caming that antific\n",
      "And yethess. anstal of thead do ther for i, welly pryprispon by meate aptent, dety symatter idealceavour enoure: thanothe, ever have miguate exulad amonalser opposity \"son asmean ancism thesi( theallified, a\n"
     ]
    }
   ],
   "source": [
    "print(get_next_n(\"And yet\", 200))\n",
    "print(get_next_n(\"And yet\", 200))\n",
    "print(get_next_n(\"And yet\", 200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "Try out different authors. Work out how much data needed to start imitating the style."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
